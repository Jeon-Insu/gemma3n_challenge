"""
LLM Iteration Task Service
ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ëª¨ë¸ë¡œ ë°˜ë³µì ì¸ ì§ˆë¬¸ì„ ìˆ˜í–‰í•˜ëŠ” íƒœìŠ¤í¬
"""
import os
import sys
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
import streamlit as st

# Import function module using direct path
import sys
import os
import importlib.util

# Get the path to function.py
function_path = os.path.join(os.path.dirname(__file__), '..', '..', 'function', 'function.py')
spec = importlib.util.spec_from_file_location("function", function_path)
function_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(function_module)

# Import the functions
run_model_iter = function_module.run_model_iter


class LLMIterationTask:
    """LLM Iteration Task class"""
    
    def __init__(self):
        self.task_name = "Screening Task"
        self.task_description = "ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ ì‚¬ìš©í•˜ì—¬ screeningì„ ìœ„í•œ LLM ëª¨ë¸ë¡œ ë°˜ë³µì ì¸ ì§ˆë¬¸ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
        
    def execute_task(self, model, task_id: str, question_key: str = "Q1", task_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Execute LLM Iteration Task.
        
        Args:
            model: LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
            task_id: íƒœìŠ¤í¬ ID
            question_key: ì§ˆë¬¸ í‚¤ ("Q1", "Q2", ...)
            task_params: íƒœìŠ¤í¬ íŒŒë¼ë¯¸í„° (ë°˜ë³µ íšŸìˆ˜ ë“±)
            
        Returns:
            Dict[str, Any]: ì‹¤í–‰ ê²°ê³¼
        """
        try:
            # ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œëœ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            video_prefix = st.session_state.get(f'video_prefix_{task_id}')
            if not video_prefix:
                return {"error": "ë¹„ë””ì˜¤ê°€ ë…¹í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë¹„ë””ì˜¤ë¥¼ ë…¹í™”í•´ì£¼ì„¸ìš”."}
            
            # ì‚¬ìš©ìžë³„ í´ë” í™•ì¸ (video_prefixì™€ ë™ì¼í•œ UUID ì‚¬ìš©)
            user_id = st.session_state.get('user_id', st.session_state.get('video_prefix', 'default_user'))
            user_record_dir = Path(f"./recordings/{user_id}")
            
            # í´ë”ê°€ ì¡´ìž¬í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë°˜í™˜
            if not user_record_dir.exists():
                return {"error": "ë¹„ë””ì˜¤ ë…¹í™” í´ë”ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ë¹„ë””ì˜¤ë¥¼ ë…¹í™”í•´ì£¼ì„¸ìš”."}
            
            # ì§ˆë¬¸ ì„¸íŠ¸ ë° ë°ì´í„° íƒ€ìž… ê°€ì ¸ì˜¤ê¸°
            from config.questions import get_question_set, get_question_data_type
            questions_list = get_question_set(question_key)
            data_type = get_question_data_type(question_key)
            
            if not questions_list:
                return {"error": f"ì§ˆë¬¸ ì„¸íŠ¸ '{question_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            # íŒŒë¼ë¯¸í„° ì„¤ì •
            if task_params:
                nI = task_params.get('nI', 1)  # ë°˜ë³µ íšŸìˆ˜
            else:
                nI = 1
            
            # ë°ì´í„° íƒ€ìž…ë³„ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            if data_type == "oneframe_image":
                # ì¤‘ê°„ í”„ë ˆìž„ ì„ íƒ (ì§ìˆ˜ì¼ ë•ŒëŠ” ì•žìª½, í™€ìˆ˜ì¼ ë•ŒëŠ” ì •ì¤‘ì•™)
                images_dir = user_record_dir / "images"
                if not images_dir.exists():
                    return {"error": f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {images_dir}"}
                
                # ëª¨ë“  í”„ë ˆìž„ íŒŒì¼ ì°¾ê¸°
                frame_files = sorted(list(images_dir.glob(f"{video_prefix}_frame_*.png")))
                if not frame_files:
                    return {"error": f"í”„ë ˆìž„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {images_dir}"}
                
                # ì¤‘ê°„ í”„ë ˆìž„ ì„ íƒ ë¡œì§
                total_frames = len(frame_files)
                if total_frames == 1:
                    # í”„ë ˆìž„ì´ 1ê°œì¼ ë•Œ: í•´ë‹¹ í”„ë ˆìž„ ì„ íƒ
                    middle_index = 0
                else:
                    # í”„ë ˆìž„ì´ ì—¬ëŸ¬ ê°œì¼ ë•Œ: ì¤‘ê°„ ì¸ë±ìŠ¤ ì„ íƒ (ì§ìˆ˜ì¼ ë•ŒëŠ” ì•žìª½)
                    middle_index = (total_frames - 1) // 2
                
                file_path = frame_files[middle_index]
                print(f"ðŸ” Debug: Selected frame {middle_index + 1} of {total_frames} frames for {question_key}")
                
                if not file_path.exists():
                    return {"error": f"ì„ íƒëœ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}
                
                # LLM ë°˜ë³µ ì§ˆë¬¸ ì‹¤í–‰ (ë‹¨ì¼ í”„ë ˆìž„)
                try:
                    # ë‹¨ì¼ í”„ë ˆìž„ ì²˜ë¦¬ ì „ì— ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
                    print(f"ðŸ”„ Clearing history for {question_key} (oneframe_image)")
                    if hasattr(model, 'clear_history'):
                        try:
                            model.clear_history()
                            print(f"âœ… History cleared successfully for {question_key}")
                        except Exception as clear_error:
                            print(f"âš ï¸ Warning: Failed to clear history for {question_key}: {clear_error}")
                    else:
                        print(f"âš ï¸ Warning: Model does not have clear_history method for {question_key}")
                    
                    log = run_model_iter(
                        model=model,
                        datatype="image",
                        file_path=str(file_path),
                        questions_list=questions_list,
                        nI=nI,
                        question_key=question_key
                    )
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ì¶”ê°€ ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
                    import gc
                    gc.collect()
                    
                    # ì¶”ê°€ ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™” ì‹œë„
                    try:
                        if hasattr(model, 'reset'):
                            model.reset()
                            print(f"âœ… Model reset completed for {question_key}")
                    except Exception as reset_error:
                        print(f"âš ï¸ Warning: Model reset failed for {question_key}: {reset_error}")
                    
                    try:
                        if hasattr(model, 'empty_cache'):
                            model.empty_cache()
                            print(f"âœ… Model cache cleared for {question_key}")
                    except Exception as cache_error:
                        print(f"âš ï¸ Warning: Model cache clear failed for {question_key}: {cache_error}")
                    
                except Exception as e:
                    print(f"Warning: Error processing single frame: {str(e)}")
                    # ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ë¡œê·¸ ìƒì„±
                    log = [{
                        "iteration": 1,
                        "questions": [],
                        "question_key": question_key,
                        "error": str(e)
                    }]
                    
                    # ê¸°ë³¸ ì‘ë‹µ ìƒì„± (ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ 0ìœ¼ë¡œ ì„¤ì •)
                    for j, question_text in enumerate(questions_list):
                        log[0]["questions"].append({
                            "question_num": j + 1,
                            "question_text": question_text,
                            "response": 0
                        })
                
            elif data_type == "allframe_image":
                # ëª¨ë“  í”„ë ˆìž„ ì‚¬ìš©
                images_dir = user_record_dir / "images"
                if not images_dir.exists():
                    return {"error": f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {images_dir}"}
                
                # ëª¨ë“  í”„ë ˆìž„ íŒŒì¼ ì°¾ê¸°
                frame_files = sorted(list(images_dir.glob(f"{video_prefix}_frame_*.png")))
                if not frame_files:
                    return {"error": f"í”„ë ˆìž„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {images_dir}"}
                
                log = []
                for frame_idx, frame_path in enumerate(frame_files):
                    try:
                        # ê° í”„ë ˆìž„ ì²˜ë¦¬ ì „ì— ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
                        print(f"ðŸ”„ Clearing history for {question_key} (allframe_image, frame {frame_idx})")
                        if hasattr(model, 'clear_history'):
                            try:
                                model.clear_history()
                                print(f"âœ… History cleared successfully for {question_key} (frame {frame_idx})")
                            except Exception as clear_error:
                                print(f"âš ï¸ Warning: Failed to clear history for {question_key} (frame {frame_idx}): {clear_error}")
                        else:
                            print(f"âš ï¸ Warning: Model does not have clear_history method for {question_key} (frame {frame_idx})")
                        
                        frame_log = run_model_iter(
                            model=model,
                            datatype="image",
                            file_path=str(frame_path),
                            questions_list=questions_list,
                            nI=1,  # ê° í”„ë ˆìž„ë‹¹ 1íšŒë§Œ ì‹¤í–‰
                            question_key=question_key
                        )
                        
                        # í”„ë ˆìž„ ì •ë³´ ì¶”ê°€
                        for iter_log in frame_log:
                            iter_log["frame_index"] = frame_idx
                            iter_log["frame_path"] = str(frame_path)
                        
                        log.extend(frame_log)
                        
                        # ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ì¶”ê°€ ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
                        import gc
                        gc.collect()
                        
                        # ì¶”ê°€ ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™” ì‹œë„
                        try:
                            if hasattr(model, 'reset'):
                                model.reset()
                                print(f"âœ… Model reset completed for {question_key} (frame {frame_idx})")
                        except Exception as reset_error:
                            print(f"âš ï¸ Warning: Model reset failed for {question_key} (frame {frame_idx}): {reset_error}")
                        
                        try:
                            if hasattr(model, 'empty_cache'):
                                model.empty_cache()
                                print(f"âœ… Model cache cleared for {question_key} (frame {frame_idx})")
                        except Exception as cache_error:
                            print(f"âš ï¸ Warning: Model cache clear failed for {question_key} (frame {frame_idx}): {cache_error}")
                        
                    except Exception as e:
                        print(f"Warning: Error processing frame {frame_idx}: {str(e)}")
                        # ì˜¤ë¥˜ê°€ ë°œìƒí•œ í”„ë ˆìž„ì— ëŒ€í•œ ê¸°ë³¸ ë¡œê·¸ ìƒì„±
                        error_log = {
                            "iteration": 1,
                            "questions": [],
                            "question_key": question_key,
                            "frame_index": frame_idx,
                            "frame_path": str(frame_path),
                            "error": str(e)
                        }
                        
                        # ê¸°ë³¸ ì‘ë‹µ ìƒì„± (ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ 0ìœ¼ë¡œ ì„¤ì •)
                        for j, question_text in enumerate(questions_list):
                            error_log["questions"].append({
                                "question_num": j + 1,
                                "question_text": question_text,
                                "response": 0
                            })
                        
                        log.append(error_log)
                
            elif data_type == "audio":
                # ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
                file_path = user_record_dir / "audio" / f"{video_prefix}_audio.wav"
                if not file_path.exists():
                    return {"error": f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}
                
                # LLM ë°˜ë³µ ì§ˆë¬¸ ì‹¤í–‰ (ì˜¤ë””ì˜¤)
                try:
                    # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì „ì— ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
                    print(f"ðŸ”„ Clearing history for {question_key} (audio)")
                    if hasattr(model, 'clear_history'):
                        try:
                            model.clear_history()
                            print(f"âœ… History cleared successfully for {question_key}")
                        except Exception as clear_error:
                            print(f"âš ï¸ Warning: Failed to clear history for {question_key}: {clear_error}")
                    else:
                        print(f"âš ï¸ Warning: Model does not have clear_history method for {question_key}")
                    
                    log = run_model_iter(
                        model=model,
                        datatype="audio",
                        file_path=str(file_path),
                        questions_list=questions_list,
                        nI=nI,
                        question_key=question_key
                    )
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ì¶”ê°€ ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
                    import gc
                    gc.collect()
                    
                    # ì¶”ê°€ ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™” ì‹œë„
                    try:
                        if hasattr(model, 'reset'):
                            model.reset()
                            print(f"âœ… Model reset completed for {question_key}")
                    except Exception as reset_error:
                        print(f"âš ï¸ Warning: Model reset failed for {question_key}: {reset_error}")
                    
                    try:
                        if hasattr(model, 'empty_cache'):
                            model.empty_cache()
                            print(f"âœ… Model cache cleared for {question_key}")
                    except Exception as cache_error:
                        print(f"âš ï¸ Warning: Model cache clear failed for {question_key}: {cache_error}")
                    
                except Exception as e:
                    print(f"Warning: Error processing audio: {str(e)}")
                    # ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ë¡œê·¸ ìƒì„±
                    log = [{
                        "iteration": 1,
                        "questions": [],
                        "question_key": question_key,
                        "error": str(e)
                    }]
                    
                    # ê¸°ë³¸ ì‘ë‹µ ìƒì„± (ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ 0ìœ¼ë¡œ ì„¤ì •)
                    for j, question_text in enumerate(questions_list):
                        log[0]["questions"].append({
                            "question_num": j + 1,
                            "question_text": question_text,
                            "response": 0
                        })
                
            else:
                return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° íƒ€ìž…ìž…ë‹ˆë‹¤: {data_type}"}
            
            # ê²°ê³¼ ì •ë¦¬
            result = {
                "task_name": self.task_name,
                "task_id": task_id,
                "question_key": question_key,
                "data_type": data_type,
                "file_path": str(file_path) if data_type != "allframe_image" else f"Multiple frames ({len(frame_files) if 'frame_files' in locals() else 0})",
                "questions": questions_list,
                "iterations": nI,
                "log": log,
                "status": "completed"
            }
            
            # ========================================
            # ë¡œê·¸ ì²˜ë¦¬ ë° ìµœì¢… ê²°ê³¼ ì¶”ì¶œ ê³µê°„
            # ========================================
            # ì—¬ê¸°ì„œ log ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            # ì˜ˆ: ê° ì§ˆë¬¸ë³„ ì‘ë‹µ í†µê³„, ì „ì²´ ì ìˆ˜ ê³„ì‚°, ìœ„í—˜ë„ í‰ê°€ ë“±
            
            # ë¡œê·¸ ë¶„ì„ ë¡œì§ ì‹¤í–‰
            processed_result = self.process_log_data(log, question_key, data_type)
            result["final_result"] = processed_result
            
            # ========================================
            # ë¡œê·¸ ì²˜ë¦¬ ê³µê°„ ë
            # ========================================
            
            return result
            
        except Exception as e:
            return {
                "error": f"íƒœìŠ¤í¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "status": "failed"
            }
    
    def get_task_info(self) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "name": self.task_name,
            "description": self.task_description,
            "type": "llm_iteration",
            "requires_video": True,
            "requires_model": True
        }
    
    def validate_prerequisites(self, task_id: str) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ì‹¤í–‰ ì „ í•„ìš”í•œ ì¡°ê±´ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤."""
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": []
        }
        
        # ë¹„ë””ì˜¤ ë…¹í™” í™•ì¸
        video_prefix = st.session_state.get(f'video_prefix_{task_id}')
        if not video_prefix:
            validation_result["valid"] = False
            validation_result["errors"].append("ë¹„ë””ì˜¤ê°€ ë…¹í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë¹„ë””ì˜¤ ë¶„í•  ì™„ë£Œ í™•ì¸
        video_split_done = st.session_state.get(f'video_split_done_{task_id}', False)
        if not video_split_done:
            validation_result["valid"] = False
            validation_result["errors"].append("ë¹„ë””ì˜¤ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì´ˆê¸°í™” í™•ì¸
        model_initialized = st.session_state.get('model_initialized', False)
        
        if not model_initialized:
            validation_result["valid"] = False
            validation_result["errors"].append("LLM ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ì„ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
        
        return validation_result
    
    def process_log_data(self, log: List[Dict], question_key: str, data_type: str) -> Dict[str, Any]:
        """
        ë¡œê·¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            log: LLM ì‹¤í–‰ ë¡œê·¸ ë°ì´í„°
            question_key: ì§ˆë¬¸ í‚¤
            data_type: ë°ì´í„° íƒ€ìž…
            
        Returns:
            Dict[str, Any]: ì²˜ë¦¬ëœ ìµœì¢… ê²°ê³¼
        """
        # ========================================
        # ë¡œê·¸ ë¶„ì„ ë° ìµœì¢… ê²°ê³¼ ì¶”ì¶œ ë¡œì§
        # ========================================
        
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        total_iterations = len(log)
        total_questions = 0
        total_responses = 0
        response_counts = {0: 0, 1: 0}  # 0, 1, ì‘ë‹µ ì¹´ìš´íŠ¸
        
        # ê° ë°˜ë³µë³„ ë¶„ì„
        for iteration in log:
            questions = iteration.get('questions', [])
            total_questions += len(questions)
            
            for question in questions:
                response = question.get('response', 0)
                total_responses += 1
                response_counts[response] = response_counts.get(response, 0) + 1
        
        # ì‘ë‹µ ë¹„ìœ¨ ê³„ì‚°
        response_rates = {}
        if total_responses > 0:
            for response, count in response_counts.items():
                response_rates[response] = count / total_responses
        
        # ë°ì´í„° íƒ€ìž…ë³„ ì¶”ê°€ ë¶„ì„
        if data_type == "allframe_image":
            # í”„ë ˆìž„ë³„ ë¶„ì„
            frame_analysis = {}
            for iteration in log:
                frame_index = iteration.get('frame_index', 0)
                if frame_index not in frame_analysis:
                    frame_analysis[frame_index] = []
                frame_analysis[frame_index].extend([q.get('response', 0) for q in iteration.get('questions', [])])
        
        # ========================================
        # Feature ì ìˆ˜ ê³„ì‚° ë¡œì§
        # ========================================
        
        # Feature ë³€ìˆ˜ ì´ˆê¸°í™”
        image_feature = 0
        audio_feature = 0
        text_feature = ""
        Q15_result = None
        
        # ê°œë³„ ì§ˆë¬¸ë³„ ê²°ê³¼ ë³€ìˆ˜ ì´ˆê¸°í™”
        Q1_result = 0
        Q2_result = 0
        Q3_result = 0
        Q4_result = 0
        Q5_result = 0
        Q6_result = 0
        Q7_result = 0
        Q8_result = 0
        Q9_result = 0
        Q10_result = 0
        Q11_result = 0
        Q12_result = 0
        Q13_result = 0
        
        # ì§ˆë¬¸ë³„ ì‘ë‹µ ì²˜ë¦¬
        if question_key == "Q1":
            # Q1: ê²°ê³¼ê°’ì„ image_featureì— ë”í•˜ê¸°
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    if response == 9:
                        
                        Q1_result = 1
        elif question_key == "Q2":
            # Q2: Q2ì™€ Q2_1ì´ ëª¨ë‘ 9ì¸ ê²½ìš°ì—ë§Œ -1
            questions_responses = []
            for iteration in log:
                for question in iteration.get('questions', []):
                    questions_responses.append(question.get('response', 0))
            
            if len(questions_responses) >= 2:
                if questions_responses[0] == 9 and questions_responses[1] == 9:
                    Q2_result = -1
                else:
                    Q2_result = 0
                    
        elif question_key == "Q3":
            # Q3: ê° í”„ë ˆìž„ë³„ë¡œ Q3ì™€ Q3_1ì´ ëª¨ë‘ 9ì¸ ê²½ìš°ë¥¼ í™•ì¸
            frame_scores = []
            for iteration in log:
                frame_index = iteration.get('frame_index', 0)
                questions = iteration.get('questions', [])
                
                # ë‘ ë²ˆì§¸ ì§ˆë¬¸ê¹Œì§€ ìžˆëŠ” ê²½ìš°ë§Œ ì¹´ìš´íŠ¸ (ì²« ë²ˆì§¸ ì§ˆë¬¸ì´ 9ì¸ ê²½ìš°)
                if len(questions) >= 2:
                    if questions[0].get('response', 0) == 9 and questions[1].get('response', 0) == 9:
                        frame_scores.append(1)
                    else:
                        frame_scores.append(0)
            
            if frame_scores:
                avg_score = sum(frame_scores) / len(frame_scores)
                if avg_score > 0.15:  # 70% ì´ìƒì˜ í”„ë ˆìž„ì—ì„œ ì¡°ê±´ ë§Œì¡±
                    
                    Q3_result = 1
                    
        elif question_key == "Q4":
            # Q4: ëª¨ë“  í”„ë ˆìž„ì˜ í‰ê· ì´ 0.3ë³´ë‹¤ ìž‘ìœ¼ë©´ 1 ë”í•˜ê¸°
            total_response = 0
            frame_count = 0
            for iteration in log:
                for question in iteration.get('questions', []):
                    total_response += question.get('response', 0)
                frame_count += 1
            
            if frame_count > 0:
                avg_response = total_response / frame_count
                if avg_response < 0.15:
                    
                    Q4_result = 1
                    
        elif question_key == "Q5":
            # Q5: ëª¨ë“  í”„ë ˆìž„ì˜ í‰ê· ì´ 0.7ë³´ë‹¤ í¬ë©´ 1 ë”í•˜ê¸°
            total_response = 0
            frame_count = 0
            for iteration in log:
                for question in iteration.get('questions', []):
                    total_response += question.get('response', 0)
                frame_count += 1
            
            if frame_count > 0:
                avg_response = total_response / frame_count
                if avg_response > 0.7:
                    
                    Q5_result = 1
                    
        elif question_key == "Q6":
            # Q6: ê²°ê³¼ê°’ì„ image_featureì— ë”í•˜ê¸°
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    
                    if response == 9:
                        Q6_result = 1
                    
        elif question_key == "Q7":
            # Q7: ëª¨ë“  í”„ë ˆìž„ì˜ í‰ê· ì´ 0.7ë³´ë‹¤ í¬ë©´ 1 ë”í•˜ê¸°
            total_response = 0
            frame_count = 0
            for iteration in log:
                for question in iteration.get('questions', []):
                    total_response += question.get('response', 0)
                frame_count += 1
            
            if frame_count > 0:
                avg_response = total_response / frame_count
                if avg_response > 0.15:
                    
                    Q7_result = 1
                    
        elif question_key == "Q8":
            # Q8: ê²°ê³¼ê°’ì„ Q8_resultì— ì €ìž¥
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    if response == 9:
                        Q8_result = 1
                    
        elif question_key == "Q9":
            # Q9: ê²°ê³¼ê°’ì„ Q9_resultì— ì €ìž¥
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    if response == 9:
                        Q9_result = 1
                    
        elif question_key == "Q10":
            # Q10: ê²°ê³¼ê°’ì„ Q10_resultì— ì €ìž¥ (9ì¸ ê²½ìš° -1ë¡œ ì²˜ë¦¬)
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    if response == 9:
                        Q10_result = -1
                    else:
                        Q10_result = 0
                    
        elif question_key == "Q11":
            # Q11: ê²°ê³¼ê°’ì„ Q11_resultì— ì €ìž¥
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    if response == 9:
                        Q11_result = 1
                    
        elif question_key == "Q12":
            # Q12: ê²°ê³¼ê°’ì„ Q12_resultì— ì €ìž¥
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    if response == 9:
                        Q12_result = 1
                    
        elif question_key == "Q13":
            # Q13: ê²°ê³¼ê°’ì„ Q13_resultì— ì €ìž¥
            for iteration in log:
                for question in iteration.get('questions', []):
                    response = question.get('response', 0)
                    if response == 9:
                        Q13_result = 1
                    
        elif question_key == "Q14":
            # Q14: text_feature ì„¤ì •
            # ê° ë°˜ë³µì—ì„œ Q14ì˜ ì‹¤ì œ ì‹¤í–‰ëœ ì§ˆë¬¸ ì‘ë‹µì„ ìˆ˜ì§‘
            q14_responses = []
            q14_1_responses = []
            q14_2_responses = []
            
            for iteration in log:
                questions = iteration.get('questions', [])
                
                # ì²« ë²ˆì§¸ ì§ˆë¬¸ì€ í•­ìƒ ìžˆìŒ
                if len(questions) >= 1:
                    q14_responses.append(questions[0].get('response', 0))  # Q14
                
                # ë‘ ë²ˆì§¸ ì§ˆë¬¸ì´ ìžˆëŠ” ê²½ìš°
                if len(questions) >= 2:
                    q14_1_responses.append(questions[1].get('response', 0))  # Q14_1
                
                # ì„¸ ë²ˆì§¸ ì§ˆë¬¸ì´ ìžˆëŠ” ê²½ìš°
                if len(questions) >= 3:
                    q14_2_responses.append(questions[2].get('response', 0))  # Q14_2
            
            # ê°€ìž¥ ë¹ˆë²ˆí•œ ì‘ë‹µì„ ì‚¬ìš©
            from collections import Counter
            
            q14_final = Counter(q14_responses).most_common(1)[0][0] if q14_responses else 0
            q14_1_final = Counter(q14_1_responses).most_common(1)[0][0] if q14_1_responses else 0
            q14_2_final = Counter(q14_2_responses).most_common(1)[0][0] if q14_2_responses else 0
            
            # text_feature ê²°ì • ë¡œì§
            if q14_final == 0:
                text_feature = "identification"
            else:
                if q14_1_final == 0:
                    text_feature = "eccentricity"
                else:
                    if q14_2_final == 9:
                        text_feature = "optimism"
                    else:
                        text_feature = "none"
              
        elif question_key == "Q15":
            # Q15: Q15_resultì— ê²°ê³¼ê°’ ì €ìž¥
            for iteration in log:
                for question in iteration.get('questions', []):
                    Q15_result = question.get('response', 0)
        
        # ìµœì¢… ê²°ê³¼ êµ¬ì„± (feature ì ìˆ˜ëŠ” execute_screening_taskì—ì„œ ê³„ì‚°)
        final_result = {
            "question_key": question_key,
            "data_type": data_type,
            "total_iterations": total_iterations,
            "total_questions": total_questions,
            "total_responses": total_responses,
            "response_counts": response_counts,
            "response_rates": response_rates,
            "analysis_summary": {
                "zero_rate": response_rates.get(0, 0),
                "one_rate": response_rates.get(1, 0),
                "nine_rate": response_rates.get(9, 0)
            },
            "question_results": {
                "Q1_result": Q1_result,
                "Q2_result": Q2_result,
                "Q3_result": Q3_result,
                "Q4_result": Q4_result,
                "Q5_result": Q5_result,
                "Q6_result": Q6_result,
                "Q7_result": Q7_result,
                "Q8_result": Q8_result,
                "Q9_result": Q9_result,
                "Q10_result": Q10_result,
                "Q11_result": Q11_result,
                "Q12_result": Q12_result,
                "Q13_result": Q13_result
            },
            "text_feature": text_feature,
            "Q15_result": Q15_result
        }
        
        # ë°ì´í„° íƒ€ìž…ë³„ ì¶”ê°€ ì •ë³´
        if data_type == "allframe_image":
            final_result["frame_analysis"] = frame_analysis
        
        # ========================================
        # ë¡œê·¸ ë¶„ì„ ë¡œì§ ë
        # ========================================
        
        return final_result
    
    def calculate_screening_scores(self, all_results: Dict[str, Dict]) -> Dict[str, int]:
        """
        ëª¨ë“  ì§ˆë¬¸ ì„¸íŠ¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ screening ë¬¸í•­ 9ê°œì˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            all_results: ëª¨ë“  ì§ˆë¬¸ ì„¸íŠ¸ì˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ {question_key: result}
            
        Returns:
            Dict[str, int]: screening ë¬¸í•­ 9ê°œì˜ ì ìˆ˜
        """
        # ì´ë¯¸ ëˆ„ì ëœ ê°’ì´ ìžˆëŠ” ê²°ê³¼ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        cumulative_result = None
        for result in all_results.values():
            if result.get('status') == 'completed' and 'final_result' in result:
                cumulative_result = result
                break
        
        if not cumulative_result:
            return {}
        
        # ì´ë¯¸ ëˆ„ì ëœ ê°’ë“¤ ì§ì ‘ ì‚¬ìš©
        final_result = cumulative_result['final_result']
        cumulative_question_results = final_result.get('question_results', {})
        cumulative_feature_scores = final_result.get('feature_scores', {})
        
        # Image_scoreì™€ Audio_score ê³„ì‚° (ëˆ„ì ëœ ê°’ ì‚¬ìš©)
        image_score = 1 if cumulative_feature_scores.get('image_feature', 0) >= 2 else 0
        audio_score = 1 if cumulative_feature_scores.get('audio_feature', 0) >= 3 else 0
        
        # Screening ë¬¸í•­ë³„ ì ìˆ˜ ê³„ì‚° (ëˆ„ì ëœ ê°’ ì‚¬ìš©)
        screening_scores = {}
        
        # ë¬¸í•­ 1: í¥ë¯¸ì €í•˜ (Q1 ë˜ëŠ” Q3 ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ 1ì´ë©´ 1)
        q1_result = cumulative_question_results.get('Q1_result', 0)
        q3_result = cumulative_question_results.get('Q3_result', 0)
        screening_scores['interest_loss'] = 1 if (q1_result == 1 or q3_result == 1) else 0

        # ë¬¸í•­ 2: ìš°ìš¸ë¬¸í•­ (image_score ë˜ëŠ” audio_score ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ 1ì´ë©´ 1)
        screening_scores['depression'] = 1 if (image_score == 1 or audio_score == 1) else 0

        # ë¬¸í•­ 3: ìž  ë¬¸í•­ (0ìœ¼ë¡œ ê³ ì •)
        screening_scores['sleep'] = 0

        # ë¬¸í•­ 4: í”¼ë¡œ ë¬¸í•­ (Q3 ë˜ëŠ” Q4 ë˜ëŠ” Q8 ë˜ëŠ” Q9 ì¤‘ 1ê°œë¼ë„ 1ì´ë©´ 1)
        q3_fatigue = cumulative_question_results.get('Q3_result', 0)
        q4_fatigue = cumulative_question_results.get('Q4_result', 0)
        q8_fatigue = cumulative_question_results.get('Q8_result', 0)
        q9_fatigue = cumulative_question_results.get('Q9_result', 0)
        screening_scores['fatigue'] = 1 if (q3_fatigue == 1 or q4_fatigue == 1 or q8_fatigue == 1 or q9_fatigue == 1) else 0

        # ë¬¸í•­ 5: ìž…ë§› (Q6ì´ 1ì´ë©´ 1)
        q6_appetite = cumulative_question_results.get('Q6_result', 0)
        screening_scores['appetite'] = 1 if q6_appetite == 1 else 0

        # ë¬¸í•­ 6: ë¶€ì •ì ê´€ë ¨ (Textê°€ optimismì´ë©´ 0, ì•„ë‹ˆë©´ Q1 ë˜ëŠ” Q7 ì¤‘ í•˜ë‚˜ë¼ë„ 1ì´ë©´ 1)
        if cumulative_feature_scores.get('text_feature') == "optimism":
            screening_scores['negative_thoughts'] = 0
        else:
            q1_negative = cumulative_question_results.get('Q1_result', 0)
            q7_negative = cumulative_question_results.get('Q7_result', 0)
            screening_scores['negative_thoughts'] = 1 if (q1_negative == 1 or q7_negative == 1) else 0

        # ë¬¸í•­ 7: ì§‘ì¤‘ë ¥ ì €í•˜ (Q12 ë˜ëŠ” Q13 ì¤‘ í•˜ë‚˜ë¼ë„ 1ì´ë©´ 1)
        q12_concentration = cumulative_question_results.get('Q12_result', 0)
        q13_concentration = cumulative_question_results.get('Q13_result', 0)
        screening_scores['concentration'] = 1 if (q12_concentration == 1 or q13_concentration == 1) else 0

        # ë¬¸í•­ 8: ëŠë ¤ì§ (Q9ì˜ ê°’ì´ 1ì´ë©´ 1)
        q9_slowness = cumulative_question_results.get('Q9_result', 0)
        screening_scores['slowness'] = 1 if q9_slowness == 1 else 0

        # ë¬¸í•­ 9: ìžì‚´ì‚¬ê³  (Q15_resultê°€ 9ì´ë©´ 1)
        screening_scores['suicidal_thoughts'] = 1 if cumulative_feature_scores.get('Q15_result') == 9 else 0
        
        return screening_scores
    
    def calculate_diagnosis(self, all_results: Dict[str, Dict]) -> str:
        """
        ëª¨ë“  ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì§„ë‹¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            all_results: ëª¨ë“  ì§ˆë¬¸ ì„¸íŠ¸ì˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ {question_key: result}
            
        Returns:
            str: "depressive" ë˜ëŠ” "normal"
        """
        # ì´ë¯¸ ëˆ„ì ëœ ê°’ì´ ìžˆëŠ” ê²°ê³¼ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        cumulative_result = None
        for result in all_results.values():
            if result.get('status') == 'completed' and 'final_result' in result:
                cumulative_result = result
                break
        
        if not cumulative_result:
            return "Typical Range"
        
        # ì´ë¯¸ ëˆ„ì ëœ ê°’ë“¤ ì§ì ‘ ì‚¬ìš©
        final_result = cumulative_result['final_result']
        cumulative_feature_scores = final_result.get('feature_scores', {})
        
        # Image_scoreì™€ Audio_score ê³„ì‚° (ëˆ„ì ëœ ê°’ ì‚¬ìš©)
        image_score = 1 if cumulative_feature_scores.get('image_feature', 0) >= 2 else 0
        audio_score = 1 if cumulative_feature_scores.get('audio_feature', 0) >= 3 else 0
        
        # Screening ì ìˆ˜ ê³„ì‚° (ëˆ„ì ëœ ê°’ ì‚¬ìš©)
        screening_scores = self.calculate_screening_scores(all_results)
        screening_total = sum(screening_scores.values())
        
        # ì§„ë‹¨ ë¡œì§ (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ)
        # 1. text_feature == 'identification' OR Q15_result == 9 â†’ DEPRESSIVE
        if (cumulative_feature_scores.get('text_feature') == "identification" or 
            cumulative_feature_scores.get('Q15_result') == 9):
            return "DEPRESSIVE"
        
        # 2. text_feature == 'optimism' â†’ NORMAL(OPTIMISM)
        elif cumulative_feature_scores.get('text_feature') == "optimism":
            return "NORMAL(OPTIMISM)"
        
        # 3. image_score == 1 AND audio_score == 1 â†’ DEPRESSIVE
        elif image_score == 1 and audio_score == 1:
            return "DEPRESSIVE"
        
        # 4. image_score == 0 AND audio_score == 0 â†’ NORMAL
        elif image_score == 0 and audio_score == 0:
            return "NORMAL"
        
        # 5. screening_total â‰¥ 7 â†’ CLINICAL EVALUATION ADVISED
        elif screening_total >= 7:
            return "CLINICAL EVALUATION ADVISED"
        
        # 6. screening_total â‰¥ 4 â†’ MONITORING SUGGESTED
        elif screening_total >= 4:
            return "MONITORING SUGGESTED"
        
        # 7. Otherwise â†’ TYPICAL RANGE
        else:
            return "TYPICAL RANGE" 